{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rubric Criteria**\n",
    "\n",
    "The number of marks for each criterion is in the brackets.\n",
    "\n",
    "- Code readability and documentation [1]\n",
    "- Q3a: `Logistic.__call__` [1]\n",
    "- Q3b: `Logistic.derivative` [2]\n",
    "- Q3c: Demonstrate Logistic [1]\n",
    "- Q4a: `CrossEntropy.__call__` [2]\n",
    "- Q4b: `CrossEntropy.derivative` [1]\n",
    "- Q4c: Demonstrate Logistic [1]\n",
    "- Q5: Grad E w.r.t. z [1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Implementing `Logistic` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(object):\n",
    "    '''\n",
    "     act = Logistic()\n",
    "     \n",
    "     Creates an object that represents the logistic function.\n",
    "     \n",
    "     Usage:\n",
    "      act = Logistic()\n",
    "      act(np.array([0., 5.]))\n",
    "     produces the numpy array\n",
    "      [0.5 , 0.62245933]\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        return\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        '''\n",
    "         y = act(z)\n",
    "         \n",
    "         Evaluates the logistic function, element-by-element, on z.\n",
    "         \n",
    "         Input:\n",
    "          z  is a numpy array\n",
    "         Output:\n",
    "          y  is a numpy array the same size as z\n",
    "        '''\n",
    "        self.dims = z.shape\n",
    "        self.n_samples = np.shape(z)[0]\n",
    "        self.dims = np.shape(z)[-1]\n",
    "        # Logistic forumla [!]\n",
    "        self.y = 1. / (1. + np.exp(-z))  # Used for derivative [!]\n",
    "        return self.y\n",
    "    \n",
    "    def derivative(self):\n",
    "        '''\n",
    "         act.derivative()\n",
    "         \n",
    "         Computes and the derivative of the logistic function\n",
    "         element-by-element.\n",
    "         Note that the __call__ function must be called before this\n",
    "         function can be called.\n",
    "         \n",
    "         Output:\n",
    "           dactdz  array the same size as z when __call__ was called\n",
    "           \n",
    "         Usage:\n",
    "           \n",
    "           dactdz = act.derivative()\n",
    "        '''\n",
    "        # Derivatives of logistic [!]\n",
    "        return self.y * (1. - self.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate `Logistic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81757448 0.10909682]\n",
      " [0.549834   0.90024951]\n",
      " [0.12455336 0.93702664]]\n"
     ]
    }
   ],
   "source": [
    "z = np.array([[1.5, -2.1],[0.2, 2.2], [-1.95, 2.7]])  # 3x2 array\n",
    "act = Logistic()\n",
    "y = act(z)   # __call__ [!]\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14914645 0.0971947 ]\n",
      " [0.24751657 0.08980033]\n",
      " [0.10903982 0.05900771]]\n"
     ]
    }
   ],
   "source": [
    "dydz = act.derivative()  # derivative [!]\n",
    "print(dydz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Implementing `CrossEntropy` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(object):\n",
    "    '''\n",
    "     E = CrossEntropy()\n",
    "     \n",
    "     Creates an object that implements the average cross-entropy loss.\n",
    "     \n",
    "     Usage:\n",
    "      E = CrossEntropy()\n",
    "      loss = E(y, t)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.dE = []\n",
    "    \n",
    "    def __call__(self, y, t):\n",
    "        '''\n",
    "         E.__call__(y, t)  or   E(y, t)\n",
    "         \n",
    "         Computes the average cross-entropy between the outputs\n",
    "         y and the targets t.\n",
    "         \n",
    "         Inputs:\n",
    "           y  array with one sample per row\n",
    "           t  array the same size as y\n",
    "           \n",
    "         Output:\n",
    "           loss  average CE loss (scalar)\n",
    "        '''\n",
    "        n_samples, dim = np.shape(t)\n",
    "        # Cross Entropy formula [!]\n",
    "        # Must divide by the number of samples [!]\n",
    "        E = -np.sum(t*np.log(y)+(1.-t)*np.log(1.-y))/n_samples\n",
    "        self.dE = (y-t) / y / (1.-y) /n_samples  # Used for derivative\n",
    "        return E\n",
    "\n",
    "    def derivative(self):\n",
    "        '''\n",
    "         E.derivative()\n",
    "         \n",
    "         Computes and the derivative of cross-entropy with respect to y.\n",
    "         Note that the __call__ function must be called before this\n",
    "         function can be called.\n",
    "         \n",
    "         Output:\n",
    "           dEdy  array the same size as y when __call__ was called\n",
    "        '''\n",
    "        # Compute the gradient of CE w.r.t. output\n",
    "        return self.dE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate `CrossEntropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40607320905408434\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1, 0],[1, 1],[0, 1]], dtype=float)\n",
    "E = CrossEntropy()\n",
    "loss = E(y, t)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40771005  0.37415214]\n",
      " [-0.60624358 -0.37026772]\n",
      " [ 0.38075802 -0.35573517]]\n"
     ]
    }
   ],
   "source": [
    "dEdy = E.derivative()\n",
    "print(dEdy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate $\\nabla_{\\hspace{-1mm}z} E(y,t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06080851  0.03636561]\n",
      " [-0.15005533 -0.03325016]\n",
      " [ 0.04151779 -0.02099112]]\n"
     ]
    }
   ],
   "source": [
    "# It's OK to re-use the code from above\n",
    "z = np.array([[1.5, -2.1],[0.2, 2.2], [-1.95, 2.7]])  # 3x2 array\n",
    "t = np.array([[1, 0],[1, 1],[0, 1]], dtype=float)\n",
    "y = act(z)\n",
    "loss = E(y, t)\n",
    "# This could be the only needed line of code\n",
    "dEdz = act.derivative() * E.derivative()  # Hadamard [!]\n",
    "print(dEdz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
